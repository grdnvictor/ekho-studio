// backend/src/agents/audio/audio-agent.ts

import { ChatOpenAI } from "@langchain/openai";
import { MemorySaver } from "@langchain/langgraph";
import { SystemMessage, HumanMessage, AIMessage } from "@langchain/core/messages";

console.log("üöÄ Initialisation de l'agent audio intelligent...");

// URL de LM Studio depuis la variable d'environnement
const LM_STUDIO_URL = process.env.LM_STUDIO_URL || 'http://localhost:1234/v1';
console.log("üåç URL LM Studio:", LM_STUDIO_URL);

const agentModel = new ChatOpenAI({
  temperature: 0.7,
  model: "local-model",
  apiKey: "lm-studio",
  configuration: {
    baseURL: LM_STUDIO_URL
  }
});

const agentCheckpointer = new MemorySaver();

// Stockage en m√©moire des conversations (remplace le stockage dans le controller)
const conversationStore = new Map<string, any[]>();

export const audioAgent = {
  async invoke(input: any, config: any) {
    console.log("ü§ñ Agent invoke appel√© avec:", {
      messagesCount: input.messages?.length,
      threadId: config.configurable?.thread_id
    });

    const threadId = config.configurable?.thread_id;
    if (!threadId) {
      throw new Error("Thread ID manquant");
    }

    // R√©cup√©rer ou initialiser l'historique pour cette session
    let conversationHistory = conversationStore.get(threadId) || [];

    // Ajouter les nouveaux messages √† l'historique
    if (input.messages && input.messages.length > 0) {
      // Prendre seulement le dernier message utilisateur
      const lastMessage = input.messages[input.messages.length - 1];
      if (lastMessage._getType() === "human") {
        conversationHistory.push(lastMessage);
        conversationStore.set(threadId, conversationHistory);
      }
    }

    console.log("üìö Historique session:", conversationHistory.length, "messages");

    // Analyser l'historique pour d√©terminer l'√©tat de la conversation
    const conversationState = analyzeConversationState(conversationHistory);
    console.log("üîç √âtat conversation:", conversationState);

    // G√©n√©rer le prompt syst√®me bas√© sur l'√©tat
    const systemPrompt = generateContextualPrompt(conversationState);

    // Construire la conversation compl√®te
    const fullConversation = [
      new SystemMessage(systemPrompt),
      ...conversationHistory
    ];

    console.log("üìû Envoi √† LM Studio avec", fullConversation.length, "messages...");

    try {
      const response = await agentModel.invoke(fullConversation);
      console.log("‚úÖ R√©ponse re√ßue de LM Studio");

      // Ajouter la r√©ponse √† l'historique
      const aiResponse = new AIMessage(response.content as string);
      conversationHistory.push(aiResponse);
      conversationStore.set(threadId, conversationHistory);

      return {
        messages: [response],
        conversationState,
        historyLength: conversationHistory.length
      };
    } catch (error) {
      console.error("‚ùå Erreur LM Studio:", error);
      throw error;
    }
  },

  // M√©thode pour vider l'historique d'une session
  clearHistory(threadId: string) {
    conversationStore.delete(threadId);
    console.log("üóëÔ∏è Historique supprim√© pour:", threadId);
  }
};

interface ConversationState {
  messageCount: number;
  hasContent: boolean;
  hasAudience: boolean;
  hasDuration: boolean;
  hasStyle: boolean;
  hasContext: boolean;
  phase: 'discovery' | 'clarification' | 'generation' | 'complete';
  collectedInfo: string[];
}

// Fonction pour analyser l'√©tat de la conversation
function analyzeConversationState(history: any[]) {
  const userMessages = history.filter(msg => msg._getType() === 'human');
  const agentMessages = history.filter(msg => msg._getType() === 'ai');

  const allText = userMessages.map(msg => msg.content.toLowerCase()).join(' ');

  const state: ConversationState = {
    messageCount: 0,
    hasContent: false,
    hasAudience: false,
    hasDuration: false,
    hasStyle: false,
    hasContext: false,
    phase: 'discovery',
    collectedInfo: []
  };

  // Analyser le contenu collect√©
  if (allText.includes('texte') || allText.includes('script') || allText.includes('contenu') || allText.length > 50) {
    state.hasContent = true;
    state.collectedInfo.push('Contenu √† vocaliser');
  }

  if (allText.includes('public') || allText.includes('audience') || allText.includes('√¢ge') ||
    allText.includes('enfant') || allText.includes('adulte') || allText.includes('professionnel')) {
    state.hasAudience = true;
    state.collectedInfo.push('Public cible');
  }

  if (allText.includes('seconde') || allText.includes('minute') || allText.includes('dur√©e') ||
    /\d+\s*(s|sec|min)/.test(allText)) {
    state.hasDuration = true;
    state.collectedInfo.push('Dur√©e souhait√©e');
  }

  if (allText.includes('style') || allText.includes('ton') || allText.includes('chaleureux') ||
    allText.includes('professionnel') || allText.includes('dynamique') || allText.includes('calme')) {
    state.hasStyle = true;
    state.collectedInfo.push('Style/ton');
  }

  if (allText.includes('radio') || allText.includes('podcast') || allText.includes('publicit√©') ||
    allText.includes('formation') || allText.includes('vid√©o')) {
    state.hasContext = true;
    state.collectedInfo.push('Contexte d\'utilisation');
  }

  // D√©terminer la phase
  const completedItems = [state.hasContent, state.hasAudience, state.hasDuration, state.hasStyle, state.hasContext];
  const completedCount = completedItems.filter(Boolean).length;

  if (completedCount === 0) {
    state.phase = 'discovery';
  } else if (completedCount < 3) {
    state.phase = 'clarification';
  } else if (completedCount >= 3 && completedCount < 5) {
    state.phase = 'generation';
  } else {
    state.phase = 'complete';
  }

  return state;
}

// Fonction pour g√©n√©rer un prompt contextuel
function generateContextualPrompt(state: any): string {
  const basePrompt = `Tu es l'Assistant Audio professionnel d'Ekho Studio, sp√©cialis√© dans la cr√©ation de contenus audio de qualit√©.

CONTEXTE ACTUEL:
- Phase: ${state.phase}
- Messages √©chang√©s: ${state.messageCount}
- Informations collect√©es: ${state.collectedInfo.join(', ') || 'Aucune'}

MISSION: Aider l'utilisateur √† cr√©er du contenu audio professionnel √©tape par √©tape.`;

  switch (state.phase) {
    case 'discovery':
      return `${basePrompt}

PHASE D√âCOUVERTE - Premier contact
Tu d√©couvres les besoins de l'utilisateur pour la premi√®re fois.

APPROCHE:
- Sois accueillant et professionnel
- Pose UNE question ouverte pour comprendre le projet global
- Demande soit le contenu √† vocaliser, soit le type de projet
- Ne submerge pas avec trop de questions

EXEMPLES DE QUESTIONS:
- "Quel type de contenu audio souhaitez-vous cr√©er ?"
- "Avez-vous d√©j√† un texte √† vocaliser ou voulez-vous que je vous aide √† le cr√©er ?"
- "Parlez-moi de votre projet audio"

Reste conversationnel et √©vite les listes √† puces.`;

    case 'clarification':
      return `${basePrompt}

PHASE CLARIFICATION - Collecte d'informations
L'utilisateur a donn√© quelques informations, il faut clarifier les d√©tails manquants.

INFORMATIONS ENCORE N√âCESSAIRES:
${!state.hasContent ? '- Le contenu exact √† vocaliser' : ''}
${!state.hasAudience ? '- Le public cible (√¢ge, contexte)' : ''}
${!state.hasDuration ? '- La dur√©e souhait√©e approximative' : ''}
${!state.hasStyle ? '- Le style/ton souhait√© (professionnel, chaleureux, etc.)' : ''}
${!state.hasContext ? '- Le contexte d\'utilisation (radio, web, formation, etc.)' : ''}

APPROCHE:
- Pose UNE SEULE question √† la fois
- Choisis l'information la plus importante manquante
- Reste naturel et conversationnel
- Explique pourquoi cette info est utile

NE redemande JAMAIS ce qui a d√©j√† √©t√© fourni !`;

    case 'generation':
      return `${basePrompt}

PHASE G√âN√âRATION - Pr√™t √† cr√©er
La plupart des informations sont collect√©es, il est temps de proposer la g√©n√©ration.

INFORMATIONS COLLECT√âES: ${state.collectedInfo.join(', ')}

APPROCHE:
- R√©sume ce qui a √©t√© collect√©
- Propose de proc√©der √† la g√©n√©ration
- Demande confirmation ou derniers ajustements
- Sois confiant et enthousiaste

EXEMPLE: "Parfait ! J'ai toutes les informations n√©cessaires. Je vais cr√©er un audio [style] de [dur√©e] pour [audience]. Souhaitez-vous que je proc√®de √† la g√©n√©ration ?"`;

    case 'complete':
      return `${basePrompt}

PHASE COMPL√àTE - Toutes les infos collect√©es
Toutes les informations principales sont disponibles.

APPROCHE:
- Confirme la g√©n√©ration
- Propose des ajustements si n√©cessaire
- Sois pr√™t √† g√©n√©rer l'audio
- Offre des options suppl√©mentaires (vitesse, effets, etc.)`;

    default:
      return basePrompt;
  }
}

console.log("‚úÖ Agent audio intelligent cr√©√©");