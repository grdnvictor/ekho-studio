// backend/src/agents/audio/audio-agent.ts

import { ChatOpenAI } from "@langchain/openai";
import { MemorySaver } from "@langchain/langgraph";
import { SystemMessage, HumanMessage, AIMessage } from "@langchain/core/messages";
import { audioGenerationTool } from "./tools/audio-generation";
import { recommendVoice } from "../../services/audio/VoiceGuide";

console.log("üöÄ Initialisation de l'agent audio structur√©...");

// URL de LM Studio depuis la variable d'environnement
const LM_STUDIO_URL = process.env.LM_STUDIO_URL || 'http://localhost:1234/v1';
console.log("üåç URL LM Studio:", LM_STUDIO_URL);

const agentModel = new ChatOpenAI({
  temperature: 0.3, // Plus bas pour des r√©ponses plus coh√©rentes
  model: "local-model",
  apiKey: "lm-studio",
  configuration: {
    baseURL: LM_STUDIO_URL
  }
});

// Ajouter les outils √† l'agent
const agentWithTools = agentModel.bindTools([audioGenerationTool]);

// Interface pour les donn√©es collect√©es √©tape par √©tape
interface CollectedData {
  step: number;
  projectType?: string;
  textContent?: string;
  targetAudience?: string;
  voiceGender?: string;
  emotionStyle?: string;
  isComplete: boolean;
}

// Interface pour une √©tape du processus
interface ProcessStep {
  name: string;
  question: string;
  validate: (answer: string) => boolean;
  process: (answer: string, data: CollectedData) => void;
}

// Interface pour la r√©ponse de l'agent
interface AgentResponse {
  messages: AIMessage[];
  conversationState: {
    phase: string;
    step: number;
  };
  historyLength: number;
  audioGenerated: boolean;
  audioUrl?: string;
  collectedInfo?: string[];
  sessionData?: CollectedData;
}

// Stockage en m√©moire des sessions avec progression √©tape par √©tape
const sessionStore = new Map<string, CollectedData>();

// D√©finition des √©tapes structur√©es
const STEPS: Record<number, ProcessStep> = {
  1: {
    name: "Type de projet",
    question: "Quel type de contenu audio souhaitez-vous cr√©er ?\n\n‚Ä¢ Publicit√© radio\n‚Ä¢ Formation/E-learning\n‚Ä¢ Podcast\n‚Ä¢ Documentaire\n‚Ä¢ Pr√©sentation\n‚Ä¢ Autre\n\nR√©pondez simplement par le type qui vous int√©resse.",
    validate: (answer: string): boolean => answer.length > 2,
    process: (answer: string, data: CollectedData): void => {
      const lower = answer.toLowerCase();
      if (lower.includes('pub') || lower.includes('radio')) {
        data.projectType = 'publicit√© radio';
      } else if (lower.includes('formation') || lower.includes('learning')) {
        data.projectType = 'formation';
      } else if (lower.includes('podcast')) {
        data.projectType = 'podcast';
      } else if (lower.includes('documentaire')) {
        data.projectType = 'documentaire';
      } else if (lower.includes('pr√©sentation')) {
        data.projectType = 'pr√©sentation';
      } else {
        data.projectType = answer.trim();
      }
    }
  },
  2: {
    name: "Contenu √† vocaliser",
    question: "Parfait ! Maintenant, quel est le texte exact que vous souhaitez faire vocaliser ?\n\n√âcrivez simplement votre texte ci-dessous :",
    validate: (answer: string): boolean => answer.length > 10,
    process: (answer: string, data: CollectedData): void => {
      data.textContent = answer.trim();
    }
  },
  3: {
    name: "Public cible",
    question: "Excellent ! Qui est votre public cible ?\n\n‚Ä¢ Enfants (moins de 12 ans)\n‚Ä¢ Adolescents (12-18 ans)\n‚Ä¢ Jeunes adultes (18-35 ans)\n‚Ä¢ Adultes (35-55 ans)\n‚Ä¢ Seniors (55+ ans)\n‚Ä¢ Professionnels\n‚Ä¢ Grand public\n\nR√©pondez simplement par la cat√©gorie qui correspond.",
    validate: (answer: string): boolean => answer.length > 2,
    process: (answer: string, data: CollectedData): void => {
      const lower = answer.toLowerCase();
      if (lower.includes('enfant')) {
        data.targetAudience = 'enfants';
      } else if (lower.includes('ado') || lower.includes('12-18')) {
        data.targetAudience = 'adolescents';
      } else if (lower.includes('jeune') || lower.includes('18-35')) {
        data.targetAudience = 'jeunes adultes';
      } else if (lower.includes('adulte') || lower.includes('35-55')) {
        data.targetAudience = 'adultes';
      } else if (lower.includes('senior') || lower.includes('55')) {
        data.targetAudience = 'seniors';
      } else if (lower.includes('professionnel')) {
        data.targetAudience = 'professionnels';
      } else if (lower.includes('grand public')) {
        data.targetAudience = 'grand public';
      } else {
        data.targetAudience = answer.trim();
      }
    }
  },
  4: {
    name: "Type de voix",
    question: "Quel type de voix pr√©f√©rez-vous ?\n\n‚Ä¢ Voix masculine\n‚Ä¢ Voix f√©minine\n‚Ä¢ Peu importe\n\nR√©pondez simplement par votre pr√©f√©rence.",
    validate: (answer: string): boolean => answer.length > 2,
    process: (answer: string, data: CollectedData): void => {
      const lower = answer.toLowerCase();
      if (lower.includes('masculin') || lower.includes('homme')) {
        data.voiceGender = 'masculine';
      } else if (lower.includes('f√©minin') || lower.includes('femme')) {
        data.voiceGender = 'feminine';
      } else {
        data.voiceGender = 'neutral';
      }
    }
  },
  5: {
    name: "Style et √©motion",
    question: "Derni√®re question ! Quel style souhaitez-vous pour votre audio ?\n\n‚Ä¢ Professionnel et neutre\n‚Ä¢ Chaleureux et amical\n‚Ä¢ Dynamique et √©nergique\n‚Ä¢ Calme et pos√©\n‚Ä¢ Dramatique et expressif\n\nR√©pondez par le style qui vous correspond.",
    validate: (answer: string): boolean => answer.length > 2,
    process: (answer: string, data: CollectedData): void => {
      const lower = answer.toLowerCase();
      if (lower.includes('professionnel')) {
        data.emotionStyle = 'professional';
      } else if (lower.includes('chaleureux') || lower.includes('amical')) {
        data.emotionStyle = 'warm';
      } else if (lower.includes('dynamique') || lower.includes('√©nergique')) {
        data.emotionStyle = 'energetic';
      } else if (lower.includes('calme') || lower.includes('pos√©')) {
        data.emotionStyle = 'calm';
      } else if (lower.includes('dramatique') || lower.includes('expressif')) {
        data.emotionStyle = 'dramatic';
      } else {
        data.emotionStyle = 'neutral';
      }
      data.isComplete = true;
    }
  }
};

export const audioAgent = {
  async invoke(input: any, config: any): Promise<AgentResponse> {
    console.log("ü§ñ Agent structur√© appel√©");

    const threadId: string = config.configurable?.thread_id;
    if (!threadId) {
      throw new Error("Thread ID manquant");
    }

    // R√©cup√©rer ou initialiser les donn√©es de session
    let sessionData: CollectedData = sessionStore.get(threadId) || {
      step: 1,
      isComplete: false
    };

    // Extraire le message utilisateur
    const userMessage = input.messages?.[input.messages.length - 1];
    const userText: string = userMessage?.content || '';

    console.log("üìä √âtat session:", {
      step: sessionData.step,
      isComplete: sessionData.isComplete,
      userMessage: userText.slice(0, 50)
    });

    try {
      // Si c'est le premier message, commencer par l'accueil
      if (sessionData.step === 1 && !userText.includes('cr√©er') && userText.length < 10) {
        const welcomeMessage = new AIMessage(
          "üéôÔ∏è Bonjour ! Je suis votre assistant audio d'Ekho Studio.\n\n" +
          "Je vais vous aider √† cr√©er votre audio professionnel en 5 √©tapes simples.\n\n" +
          STEPS[1].question
        );

        return {
          messages: [welcomeMessage],
          conversationState: { phase: 'step_1', step: 1 },
          historyLength: 1,
          audioGenerated: false
        };
      }

      // Si toutes les √©tapes sont termin√©es, g√©n√©rer l'audio
      if (sessionData.isComplete) {
        console.log("üéµ Toutes les √©tapes termin√©es, g√©n√©ration audio...");
        return await this.generateAudio(sessionData, threadId);
      }

      // Traiter la r√©ponse utilisateur pour l'√©tape actuelle
      const currentStep: ProcessStep | undefined = STEPS[sessionData.step];

      if (currentStep && currentStep.validate(userText)) {
        // Traiter la r√©ponse
        currentStep.process(userText, sessionData);
        sessionData.step++;

        // Sauvegarder les donn√©es
        sessionStore.set(threadId, sessionData);

        console.log("‚úÖ √âtape", sessionData.step - 1, "valid√©e:", {
          projectType: sessionData.projectType,
          textContent: sessionData.textContent?.slice(0, 30),
          targetAudience: sessionData.targetAudience,
          voiceGender: sessionData.voiceGender,
          emotionStyle: sessionData.emotionStyle
        });

        // Si toutes les √©tapes sont termin√©es, g√©n√©rer
        if (sessionData.isComplete) {
          console.log("üéØ Toutes les informations collect√©es, g√©n√©ration...");
          return await this.generateAudio(sessionData, threadId);
        }

        // Passer √† l'√©tape suivante
        const nextStep: ProcessStep | undefined = STEPS[sessionData.step];
        if (nextStep) {
          const responseMessage = new AIMessage(
            `‚úÖ Parfait !\n\n**√âtape ${sessionData.step}/5** - ${nextStep.name}\n\n${nextStep.question}`
          );

          return {
            messages: [responseMessage],
            conversationState: { phase: `step_${sessionData.step}`, step: sessionData.step },
            historyLength: sessionData.step,
            audioGenerated: false,
            collectedInfo: this.getCollectedInfo(sessionData)
          };
        }
      } else {
        // R√©ponse invalide, redemander
        const errorMessage = new AIMessage(
          `‚ùå Je n'ai pas bien compris votre r√©ponse.\n\n` +
          `**√âtape ${sessionData.step}/5** - ${currentStep?.name || 'Inconnue'}\n\n${currentStep?.question || 'Question non trouv√©e'}`
        );

        return {
          messages: [errorMessage],
          conversationState: { phase: `step_${sessionData.step}`, step: sessionData.step },
          historyLength: sessionData.step,
          audioGenerated: false
        };
      }

      // Fallback si aucune condition n'est remplie
      throw new Error("√âtat de conversation non g√©r√©");

    } catch (error: unknown) {
      console.error("‚ùå Erreur dans l'agent:", error);
      const errorMessage = new AIMessage(
        "‚ùå Une erreur s'est produite. Recommen√ßons depuis le d√©but.\n\n" + STEPS[1].question
      );

      // Reset la session
      sessionStore.set(threadId, { step: 1, isComplete: false });

      return {
        messages: [errorMessage],
        conversationState: { phase: 'step_1', step: 1 },
        historyLength: 1,
        audioGenerated: false
      };
    }
  },

  async generateAudio(sessionData: CollectedData, threadId: string): Promise<AgentResponse> {
    console.log("üéµ G√©n√©ration audio avec donn√©es:", sessionData);

    try {
      // V√©rifier que toutes les donn√©es n√©cessaires sont pr√©sentes
      if (!sessionData.textContent) {
        throw new Error("Contenu textuel manquant");
      }

      // Choisir la voix optimale
      const voiceName: string = this.selectOptimalVoice(sessionData);

      // Pr√©parer les param√®tres
      const generationParams = {
        text: sessionData.textContent,
        voiceName: voiceName,
        emotion: sessionData.emotionStyle || 'neutral',
        speed: 1.0,
        effects: []
      };

      console.log("üéØ Param√®tres g√©n√©ration:", generationParams);

      // G√©n√©rer l'audio
      const audioResult = await audioGenerationTool.invoke(generationParams);

      if (audioResult.success) {
        const summaryMessage = new AIMessage(
          `üéâ **Audio g√©n√©r√© avec succ√®s !**\n\n` +
          `üìã **R√©capitulatif de votre projet :**\n` +
          `‚Ä¢ **Type :** ${sessionData.projectType || 'Non sp√©cifi√©'}\n` +
          `‚Ä¢ **Public :** ${sessionData.targetAudience || 'Non sp√©cifi√©'}\n` +
          `‚Ä¢ **Voix :** ${this.getVoiceDisplayName(voiceName)}\n` +
          `‚Ä¢ **Style :** ${this.getStyleDisplayName(sessionData.emotionStyle || 'neutral')}\n` +
          `‚Ä¢ **Dur√©e :** ~${('duration' in audioResult ? audioResult.duration : 0)}s\n\n` +
          `üéß Vous pouvez maintenant √©couter et t√©l√©charger votre audio ci-dessus.\n\n` +
          `üí° **Besoin de modifications ?** Tapez "nouveau" pour cr√©er un autre audio ou "modifier [√©l√©ment]" pour ajuster quelque chose.`
        );

        // Reset pour un nouveau projet
        sessionStore.delete(threadId);

        return {
          messages: [summaryMessage],
          conversationState: { phase: 'complete', step: 6 },
          historyLength: 6,
          audioGenerated: true,
          audioUrl: ('url' in audioResult) ? audioResult.url : undefined,
          sessionData: sessionData
        };
      } else {
        throw new Error(('error' in audioResult ? audioResult.error : audioResult.message) || "√âchec de g√©n√©ration");      }
    } catch (error: unknown) {
      console.error("‚ùå Erreur g√©n√©ration:", error);
      const errorMessage = new AIMessage(
        `‚ùå D√©sol√©, une erreur s'est produite lors de la g√©n√©ration :\n${error instanceof Error ? error.message : 'Erreur inconnue'}\n\n` +
        `Voulez-vous r√©essayer ? Tapez "oui" pour relancer ou "nouveau" pour recommencer.`
      );

      return {
        messages: [errorMessage],
        conversationState: { phase: 'error', step: sessionData.step },
        historyLength: sessionData.step,
        audioGenerated: false
      };
    }
  },

  selectOptimalVoice(sessionData: CollectedData): string {
    // Recommandation intelligente bas√©e sur les donn√©es collect√©es
    const recommendation: string = recommendVoice({
      projectType: sessionData.projectType,
      targetAudience: sessionData.targetAudience,
      emotion: sessionData.emotionStyle,
      gender: sessionData.voiceGender
    });

    console.log("üé§ Voix recommand√©e:", recommendation);
    return recommendation;
  },

  getVoiceDisplayName(voiceName: string): string {
    const voiceDisplayNames: Record<string, string> = {
      'aoede': 'Aoede (f√©minine chaleureuse)',
      'achernar': 'Achernar (masculine forte)',
      'callirrhoe': 'Callirrhoe (jeune f√©minine)',
      'charon': 'Charon (masculine profonde)',
      'despina': 'Despina (f√©minine moderne)',
      'orus': 'Orus (masculine claire)',
      'pulcherrima': 'Pulcherrima (f√©minine √©l√©gante)',
      'vindemiatrix': 'Vindemiatrix (f√©minine expressive)',
      'zephyr': 'Zephyr (neutre apaisante)',
      'sadachbia': 'Sadachbia (neutre traditionnelle)',
      'fenrir': 'Fenrir (masculine dramatique)'
    };

    return voiceDisplayNames[voiceName] || voiceName;
  },

  getStyleDisplayName(style: string): string {
    const styleNames: Record<string, string> = {
      'professional': 'Professionnel',
      'warm': 'Chaleureux',
      'energetic': 'Dynamique',
      'calm': 'Calme',
      'dramatic': 'Dramatique',
      'neutral': 'Naturel'
    };

    return styleNames[style] || style;
  },

  getCollectedInfo(sessionData: CollectedData): string[] {
    const info: string[] = [];
    if (sessionData.projectType) info.push(`Type: ${sessionData.projectType}`);
    if (sessionData.textContent) info.push('Contenu fourni');
    if (sessionData.targetAudience) info.push(`Public: ${sessionData.targetAudience}`);
    if (sessionData.voiceGender) info.push(`Voix: ${sessionData.voiceGender}`);
    if (sessionData.emotionStyle) info.push(`Style: ${sessionData.emotionStyle}`);
    return info;
  },

  // M√©thode pour vider l'historique d'une session
  clearHistory(threadId: string): void {
    sessionStore.delete(threadId);
    console.log("üóëÔ∏è Session supprim√©e:", threadId);
  }
};

console.log("‚úÖ Agent audio structur√© cr√©√©");