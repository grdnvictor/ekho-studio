import { ChatOpenAI } from "@langchain/openai";

console.log("üöÄ Initialisation de l'agent audio intelligent...");

// URL de LM Studio depuis la variable d'environnement
const LM_STUDIO_URL = process.env.LM_STUDIO_URL || 'http://localhost:1234/v1';
console.log("üåç URL LM Studio:", LM_STUDIO_URL);

const agentModel = new ChatOpenAI({
  temperature: 0.7,
  model: "local-model",
  apiKey: "lm-studio",
  configuration: {
    baseURL: LM_STUDIO_URL
  }
});

// Agent conversationnel simple qui pose les bonnes questions
export const audioAgent = {
  async invoke(input: any, config: any) {
    console.log("ü§ñ Agent invoke appel√© avec:", {
      messagesCount: input.messages?.length,
      config: config.configurable?.thread_id
    });

    // Extraire le message utilisateur
    const userMessage =
      input.messages.find(
        (msg: { _getType: () => string }) => msg._getType() === "human",
      )?.content || "";
    console.log("üë§ Message utilisateur:", userMessage);

    // Prompt syst√®me pour l'agent conversationnel
    const systemPrompt = `Tu es l'Assistant Audio professionnel d'Ekho Studio. 

MISSION: Aider l'utilisateur √† cr√©er du contenu audio de qualit√© professionnelle.

√âTAPES OBLIGATOIRES:
1. Analyser la demande utilisateur
2. Poser les questions essentielles manquantes
3. Recommander des solutions audio
4. Proposer la g√©n√©ration quand toutes les infos sont collect√©es

QUESTIONS ESSENTIELLES √Ä POSER (si pas mentionn√©es):
- Quel est le contenu/texte √† vocaliser ?
- Quel est le public cible ? (√¢ge, contexte)
- Quelle est la dur√©e souhait√©e ?
- Quel style/ton ? (professionnel, chaleureux, dynamique, etc.)
- Quelle utilisation ? (pub radio, podcast, formation, etc.)

R√àGLES:
- Pose UNE SEULE question √† la fois pour ne pas surcharger
- Sois conversationnel et professionnel
- Propose des exemples concrets
- Ne g√©n√®re de l'audio que quand tu as assez d'informations
- Utilise des √©mojis pour rendre √ßa plus engageant

R√©ponds toujours en fran√ßais avec un ton expert mais accessible.`;

    // Construire la conversation compl√®te
    const conversation = [
      { role: "system", content: systemPrompt },
      { role: "user", content: userMessage }
    ];

    console.log("üìû Envoi √† LM Studio...");

    try {
      const response = await agentModel.invoke(conversation);
      console.log("‚úÖ R√©ponse re√ßue de LM Studio");

      return {
        messages: [response]
      };
    } catch (error) {
      console.error("‚ùå Erreur LM Studio:", error);
      throw error;
    }
  }
};

console.log("‚úÖ Agent audio intelligent cr√©√©");