// backend/src/agents/audio/audio-agent.ts

import { ChatOpenAI } from "@langchain/openai";
import { MemorySaver } from "@langchain/langgraph";
import { SystemMessage, HumanMessage, AIMessage } from "@langchain/core/messages";
import { audioGenerationTool } from "./tools/audio-generation";

console.log("üöÄ Initialisation de l'agent audio intelligent...");

// URL de LM Studio depuis la variable d'environnement
const LM_STUDIO_URL = process.env.LM_STUDIO_URL || 'http://localhost:1234/v1';
console.log("üåç URL LM Studio:", LM_STUDIO_URL);

const agentModel = new ChatOpenAI({
  temperature: 0.7,
  model: "local-model",
  apiKey: "lm-studio",
  configuration: {
    baseURL: LM_STUDIO_URL
  }
});

// Ajouter les outils √† l'agent
const agentWithTools = agentModel.bindTools([audioGenerationTool]);

const agentCheckpointer = new MemorySaver();

// Stockage en m√©moire des conversations
const conversationStore = new Map<string, any[]>();

export const audioAgent = {
  async invoke(input: any, config: any) {
    console.log("ü§ñ Agent invoke appel√© avec:", {
      messagesCount: input.messages?.length,
      threadId: config.configurable?.thread_id
    });

    const threadId = config.configurable?.thread_id;
    if (!threadId) {
      throw new Error("Thread ID manquant");
    }

    // R√©cup√©rer ou initialiser l'historique pour cette session
    let conversationHistory = conversationStore.get(threadId) || [];

    // Ajouter les nouveaux messages √† l'historique
    if (input.messages && input.messages.length > 0) {
      const lastMessage = input.messages[input.messages.length - 1];
      if (lastMessage._getType() === "human") {
        conversationHistory.push(lastMessage);
        conversationStore.set(threadId, conversationHistory);
      }
    }

    console.log("üìö Historique session:", conversationHistory.length, "messages");

    // Analyser l'historique pour d√©terminer l'√©tat de la conversation
    const conversationState = analyzeConversationState(conversationHistory);
    console.log("üîç √âtat conversation:", conversationState);

    // G√©n√©rer le prompt syst√®me bas√© sur l'√©tat
    const systemPrompt = generateContextualPrompt(conversationState);

    // Construire la conversation compl√®te
    const fullConversation = [
      new SystemMessage(systemPrompt),
      ...conversationHistory
    ];

    console.log("üìû Envoi √† LM Studio avec", fullConversation.length, "messages...");

    try {
      // D√©terminer si on doit g√©n√©rer de l'audio
      const shouldGenerateAudio = conversationState.phase === 'generation' &&
        conversationState.hasContent &&
        conversationState.collectedInfo.length >= 3;

      let response;

      if (shouldGenerateAudio) {
        console.log("üéµ Conditions r√©unies pour g√©n√©ration audio");

        // Extraire le texte √† vocaliser depuis l'historique
        const textToGenerate = extractTextFromHistory(conversationHistory);
        const voiceParams = extractVoiceParamsFromHistory(conversationHistory, conversationState);

        if (textToGenerate) {
          console.log("üéØ G√©n√©ration audio avec:", { textToGenerate: textToGenerate.slice(0, 50), voiceParams });

          try {
            // Appeler l'outil de g√©n√©ration audio
            const audioResult = await audioGenerationTool.invoke({
              text: textToGenerate,
              voiceName: voiceParams.voiceName,
              emotion: voiceParams.emotion,
              speed: voiceParams.speed,
              effects: voiceParams.effects
            });

            console.log("‚úÖ R√©sultat g√©n√©ration:", audioResult);

            if (audioResult.success) {
              const audioResponse = new AIMessage(
                `üéâ Parfait ! J'ai g√©n√©r√© votre audio avec succ√®s !\n\n` +
                `üìã **R√©capitulatif** :\n` +
                `‚Ä¢ Texte : "${textToGenerate.slice(0, 100)}${textToGenerate.length > 100 ? '...' : ''}"\n` +
                `‚Ä¢ Voix : ${voiceParams.voiceName}\n` +
                `‚Ä¢ Style : ${voiceParams.emotion || 'naturel'}\n` +
                `‚Ä¢ Dur√©e : ~${audioResult.duration}s\n\n` +
                `üéß Vous pouvez maintenant √©couter votre audio ci-dessous. Si vous souhaitez des ajustements (vitesse, style, voix diff√©rente), faites-le moi savoir !`
              );

              conversationHistory.push(audioResponse);
              conversationStore.set(threadId, conversationHistory);

              return {
                messages: [audioResponse],
                conversationState: { ...conversationState, phase: 'complete' },
                historyLength: conversationHistory.length,
                audioGenerated: true,
                audioUrl: audioResult.url
              };
            } else {
              throw new Error(audioResult.error || "√âchec de g√©n√©ration");
            }
          } catch (audioError) {
            console.error("‚ùå Erreur g√©n√©ration audio:", audioError);
            const errorResponse = new AIMessage(
              `‚ùå Je rencontre une difficult√© technique pour g√©n√©rer l'audio. L'erreur est : ${audioError.message}\n\n` +
              `Pouvons-nous r√©essayer ? Ou souhaitez-vous ajuster quelque chose ?`
            );

            conversationHistory.push(errorResponse);
            conversationStore.set(threadId, conversationHistory);

            return {
              messages: [errorResponse],
              conversationState,
              historyLength: conversationHistory.length,
              audioGenerated: false
            };
          }
        }
      }

      // R√©ponse normale avec l'agent LLM
      response = await agentWithTools.invoke(fullConversation);
      console.log("‚úÖ R√©ponse re√ßue de LM Studio");

      // Ajouter la r√©ponse √† l'historique
      const aiResponse = new AIMessage(response.content as string);
      conversationHistory.push(aiResponse);
      conversationStore.set(threadId, conversationHistory);

      return {
        messages: [response],
        conversationState,
        historyLength: conversationHistory.length,
        audioGenerated: false
      };
    } catch (error) {
      console.error("‚ùå Erreur LM Studio:", error);
      throw error;
    }
  },

  // M√©thode pour vider l'historique d'une session
  clearHistory(threadId: string) {
    conversationStore.delete(threadId);
    console.log("üóëÔ∏è Historique supprim√© pour:", threadId);
  }
};

// Fonction pour extraire le texte √† vocaliser depuis l'historique
function extractTextFromHistory(history: any[]): string | null {
  const userMessages = history.filter(msg => msg._getType() === 'human');

  for (const message of userMessages.reverse()) {
    const content = message.content.toLowerCase();

    // Chercher des mots-cl√©s indiquant du contenu √† vocaliser
    if (content.includes('texte:') || content.includes('script:') || content.includes('contenu:')) {
      // Extraire le texte apr√®s le ':'
      const match = message.content.match(/(?:texte|script|contenu)\s*:\s*(.+)/i);
      if (match) return match[1].trim();
    }

    // Si le message est assez long, probablement du contenu
    if (message.content.length > 50 && !content.includes('?')) {
      return message.content.trim();
    }
  }

  // Fallback: chercher le message le plus long
  const longestMessage = userMessages.reduce((longest, current) =>
      current.content.length > longest.content.length ? current : longest,
    { content: '' }
  );

  return longestMessage.content.length > 20 ? longestMessage.content : null;
}

// Fonction pour extraire les param√®tres de voix depuis l'historique
function extractVoiceParamsFromHistory(history: any[], state: any) {
  const allText = history
    .filter(msg => msg._getType() === 'human')
    .map(msg => msg.content.toLowerCase())
    .join(' ');

  const params = {
    voiceName: "Aoede", // Par d√©faut
    emotion: "neutral",
    speed: 1,
    effects: []
  };

  // Analyser le style/√©motion
  if (allText.includes('chaleureux')) params.emotion = "warm";
  else if (allText.includes('professionnel')) params.emotion = "professional";
  else if (allText.includes('dynamique')) params.emotion = "energetic";
  else if (allText.includes('calme')) params.emotion = "calm";

  // Analyser la voix souhait√©e
  if (allText.includes('f√©minin') || allText.includes('femme')) params.voiceName = "Aoede";
  else if (allText.includes('masculin') || allText.includes('homme')) params.voiceName = "Atlas";
  else if (allText.includes('jeune')) params.voiceName = "Nova";

  // Analyser la vitesse
  if (allText.includes('rapide') || allText.includes('vite')) params.speed = 1.2;
  else if (allText.includes('lent') || allText.includes('pos√©')) params.speed = 0.8;

  return params;
}

// Fonction pour analyser l'√©tat de la conversation
function analyzeConversationState(history: any[]) {
  const userMessages = history.filter(msg => msg._getType() === 'human');
  const agentMessages = history.filter(msg => msg._getType() === 'ai');

  const allText = userMessages.map(msg => msg.content.toLowerCase()).join(' ');

  const state = {
    messageCount: userMessages.length,
    hasContent: false,
    hasAudience: false,
    hasDuration: false,
    hasStyle: false,
    hasContext: false,
    phase: 'discovery', // discovery, clarification, generation, complete
    collectedInfo: []
  };

  // Analyser le contenu collect√©
  if (allText.includes('texte') || allText.includes('script') || allText.includes('contenu') ||
    userMessages.some(msg => msg.content.length > 50)) {
    state.hasContent = true;
    state.collectedInfo.push('Contenu √† vocaliser');
  }

  if (allText.includes('public') || allText.includes('audience') || allText.includes('√¢ge') ||
    allText.includes('enfant') || allText.includes('adulte') || allText.includes('professionnel')) {
    state.hasAudience = true;
    state.collectedInfo.push('Public cible');
  }

  if (allText.includes('seconde') || allText.includes('minute') || allText.includes('dur√©e') ||
    /\d+\s*(s|sec|min)/.test(allText)) {
    state.hasDuration = true;
    state.collectedInfo.push('Dur√©e souhait√©e');
  }

  if (allText.includes('style') || allText.includes('ton') || allText.includes('chaleureux') ||
    allText.includes('professionnel') || allText.includes('dynamique') || allText.includes('calme')) {
    state.hasStyle = true;
    state.collectedInfo.push('Style/ton');
  }

  if (allText.includes('radio') || allText.includes('podcast') || allText.includes('publicit√©') ||
    allText.includes('formation') || allText.includes('vid√©o')) {
    state.hasContext = true;
    state.collectedInfo.push('Contexte d\'utilisation');
  }

  // D√©terminer la phase
  const completedItems = [state.hasContent, state.hasAudience, state.hasDuration, state.hasStyle, state.hasContext];
  const completedCount = completedItems.filter(Boolean).length;

  if (completedCount === 0) {
    state.phase = 'discovery';
  } else if (completedCount < 3) {
    state.phase = 'clarification';
  } else if (completedCount >= 3 && state.hasContent) {
    state.phase = 'generation';
  } else {
    state.phase = 'complete';
  }

  return state;
}

// Fonction pour g√©n√©rer un prompt contextuel
function generateContextualPrompt(state: any): string {
  const basePrompt = `Tu es l'Assistant Audio professionnel d'Ekho Studio, sp√©cialis√© dans la cr√©ation de contenus audio de qualit√©.

CONTEXTE ACTUEL:
- Phase: ${state.phase}
- Messages √©chang√©s: ${state.messageCount}
- Informations collect√©es: ${state.collectedInfo.join(', ') || 'Aucune'}

MISSION: Aider l'utilisateur √† cr√©er du contenu audio professionnel √©tape par √©tape.

IMPORTANT: Tu as acc√®s √† un outil de g√©n√©ration audio. Quand tu as assez d'informations (phase g√©n√©ration), tu peux proposer de cr√©er l'audio imm√©diatement.`;

  switch (state.phase) {
    case 'discovery':
      return `${basePrompt}

PHASE D√âCOUVERTE - Premier contact
Tu d√©couvres les besoins de l'utilisateur pour la premi√®re fois.

APPROCHE:
- Sois accueillant et professionnel
- Pose UNE question ouverte pour comprendre le projet global
- Demande soit le contenu √† vocaliser, soit le type de projet
- Ne submerge pas avec trop de questions

EXEMPLES DE QUESTIONS:
- "Quel type de contenu audio souhaitez-vous cr√©er ?"
- "Avez-vous d√©j√† un texte √† vocaliser ou voulez-vous que je vous aide √† le cr√©er ?"
- "Parlez-moi de votre projet audio"

Reste conversationnel et √©vite les listes √† puces.`;

    case 'clarification':
      return `${basePrompt}

PHASE CLARIFICATION - Collecte d'informations
L'utilisateur a donn√© quelques informations, il faut clarifier les d√©tails manquants.

INFORMATIONS ENCORE N√âCESSAIRES:
${!state.hasContent ? '- Le contenu exact √† vocaliser' : ''}
${!state.hasAudience ? '- Le public cible (√¢ge, contexte)' : ''}
${!state.hasDuration ? '- La dur√©e souhait√©e approximative' : ''}
${!state.hasStyle ? '- Le style/ton souhait√© (professionnel, chaleureux, etc.)' : ''}
${!state.hasContext ? '- Le contexte d\'utilisation (radio, web, formation, etc.)' : ''}

APPROCHE:
- Pose UNE SEULE question √† la fois
- Choisis l'information la plus importante manquante
- Reste naturel et conversationnel
- Explique pourquoi cette info est utile

NE redemande JAMAIS ce qui a d√©j√† √©t√© fourni !`;

    case 'generation':
      return `${basePrompt}

PHASE G√âN√âRATION - Pr√™t √† cr√©er
La plupart des informations sont collect√©es, il est temps de proposer la g√©n√©ration.

INFORMATIONS COLLECT√âES: ${state.collectedInfo.join(', ')}

APPROCHE:
- R√©sume ce qui a √©t√© collect√©
- Propose de proc√©der √† la g√©n√©ration IMM√âDIATEMENT
- Sois confiant et enthousiaste
- Annonce que l'audio va √™tre cr√©√©

IMPORTANT: Tu peux maintenant g√©n√©rer l'audio r√©ellement ! L'outil va cr√©er un fichier MP3/WAV que l'utilisateur pourra √©couter.

EXEMPLE: "Parfait ! J'ai toutes les informations n√©cessaires. Je vais cr√©er votre audio [style] maintenant. G√©n√©ration en cours..."`;

    case 'complete':
      return `${basePrompt}

PHASE COMPL√àTE - Audio g√©n√©r√© ou pr√™t
L'audio a √©t√© g√©n√©r√© ou toutes les informations sont disponibles.

APPROCHE:
- Pr√©sente le r√©sultat
- Propose des ajustements si n√©cessaire
- Offre des options suppl√©mentaires (variations, autres versions)
- Sois fier du travail accompli`;

    default:
      return basePrompt;
  }
}

console.log("‚úÖ Agent audio intelligent cr√©√©");