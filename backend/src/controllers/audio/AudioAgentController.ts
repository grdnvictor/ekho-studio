// backend/src/controllers/audio/AudioAgentController.ts
import { Request, Response } from "express";
import { audioAgent } from "@/agents/audio/audio-agent";
import { AudioAgentChatContractType } from "@/contracts/api/AudioAgentContracts";
import { ValidatedRequest } from "@/types";
import { AIMessage, HumanMessage } from "@langchain/core/messages";

interface AgentResult {
  messages: AIMessage[];
  conversationState: AudioAgentControllerState;
  historyLength: number;
  audioGenerated: boolean;
  audioUrl: any;
  context?: {
    textContent?: string;
    targetAudience?: string;
    voicePreference?: string;
    emotionStyle?: string;
    projectType?: string;
  };
}

interface AudioAgentControllerState {
  phase: string;
  messageCount: number;
  hasContent: boolean;
  hasAudience: boolean;
  hasDuration: boolean;
  hasStyle: boolean;
  hasContext: boolean;
  hasVoice: boolean;  // Ajout√© car utilis√© dans analyzeAgentResponse
  collectedInfo: never[];
}

interface AudioAgentResponse {
  messages: AIMessage[];
  conversationState: AudioAgentControllerState;
  historyLength: number;
  audioGenerated: boolean;
  audioUrl: any;
  context: {
    textContent?: string;
    targetAudience?: string;
    voicePreference?: string;
    emotionStyle?: string;
    projectType?: string;
  };
}

export class AudioAgentController {
  static async chat(request: Request, response: Response): Promise<void> {
    console.log("üéØ === DEBUT AudioAgentController.chat ===");

    try {
      const validatedRequest = request as ValidatedRequest<AudioAgentChatContractType>;
      const { message, sessionId, context } = validatedRequest.validated.body;

      const finalSessionId = sessionId || `session_${Date.now()}`;

      console.log("üì¶ Donn√©es re√ßues:", {
        message: message?.slice(0, 100),
        sessionId: finalSessionId,
        context,
        hasContext: !!context
      });

      const config = {
        configurable: {
          thread_id: finalSessionId,
        },
      };

      // Ne PAS modifier le message avec le contexte - laisser l'agent analyser naturellement
      console.log("üìù Message original envoy√© √† l'agent:", message);

      // Cr√©er le message utilisateur sans modification
      const userMessage = new HumanMessage(message);

      console.log("üöÄ Envoi √† l'agent...");

      const result = await audioAgent.invoke(
        { messages: [userMessage] },
        config
      ) as AgentResult;

      const responseContent = result.messages[0].content;
      const conversationState = result.conversationState;

      console.log("üìù R√©ponse agent:", responseContent?.slice(0, 200));
      console.log("üìä √âtat conversation:", conversationState);
      console.log("üéµ Audio g√©n√©r√©:", result.audioGenerated);

      // Analyser la r√©ponse pour d√©terminer les actions possibles
      const analysis = AudioAgentController.analyzeAgentResponse(
        responseContent as string,
        conversationState,
        result.context || {} // Utilisation d'un objet vide par d√©faut
      );

      // Construire la r√©ponse enrichie
      const responseData = {
        success: true,
        sessionId: finalSessionId,
        response: responseContent,
        needsMoreInfo: analysis.needsMoreInfo,
        missingInfo: analysis.missingInfo,
        suggestions: analysis.suggestions,
        nextSteps: analysis.nextSteps,
        canProceed: analysis.canProceed,
        readyToGenerate: analysis.readyToGenerate,
        conversationLength: result.historyLength,
        collectedInfo: conversationState?.collectedInfo || [],
        phase: conversationState?.phase || 'discovery',

        // Nouvelles informations enrichies
        audioGenerated: result.audioGenerated || false,
        audioUrl: result.audioUrl || null,
        context: result.context || {},

        // M√©tadonn√©es de session
        metadata: {
          timestamp: new Date().toISOString(),
          processingTime: Date.now(),
          messageCount: result.historyLength,
          hasAudioContent: !!result.audioUrl
        }
      };

      // Log de la r√©ponse finale
      console.log("üéØ R√©ponse finale:", {
        success: responseData.success,
        phase: responseData.phase,
        audioGenerated: responseData.audioGenerated,
        collectedInfoCount: responseData.collectedInfo.length
      });

      response.status(200).json(responseData);

    } catch (error: unknown) {
      console.error("‚ùå Erreur dans AudioAgentController.chat:", error);

      // D√©terminer le type d'erreur et le code de statut appropri√©
      let statusCode = 500;
      let errorType = "INTERNAL_ERROR";
      let userMessage = "Erreur lors de la communication avec l'agent audio";

      if (error instanceof Error) {
        if (error.message.includes("Thread ID")) {
          statusCode = 400;
          errorType = "INVALID_SESSION";
          userMessage = "Identifiant de session invalide";
        } else if (error.message.includes("timeout") || error.message.includes("network")) {
          statusCode = 503;
          errorType = "SERVICE_UNAVAILABLE";
          userMessage = "Service temporairement indisponible";
        } else if (error.message.includes("rate limit")) {
          statusCode = 429;
          errorType = "RATE_LIMIT";
          userMessage = "Trop de requ√™tes, veuillez patienter";
        }
      }

      const errorResponse = {
        success: false,
        error: userMessage,
        errorType,
        details: error instanceof Error ? error.message : "Erreur inconnue",
        timestamp: new Date().toISOString(),
        suggestions: [
          "V√©rifiez votre connexion internet",
          "R√©essayez dans quelques instants",
          "Contactez le support si le probl√®me persiste"
        ]
      };

      console.log("üì§ R√©ponse d'erreur:", errorResponse);
      response.status(statusCode).json(errorResponse);
    }
  }

  /**
   * Analyse intelligente de la r√©ponse de l'agent avec contexte enrichi
   */
  private static analyzeAgentResponse(
    content: string,
    state: any,
    context: any = {}
  ): {
    needsMoreInfo: boolean;
    missingInfo: string[];
    suggestions: string[];
    nextSteps: string[];
    canProceed: boolean;
    readyToGenerate: boolean;
  } {
    const lowerContent = content.toLowerCase();

    // D√©terminer les infos manquantes bas√© sur l'√©tat et le contexte
    const missingInfo = [];
    if (!state?.hasContent && !context?.textContent) {
      missingInfo.push('Contenu √† vocaliser');
    }
    if (!state?.hasAudience && !context?.targetAudience) {
      missingInfo.push('Public cible');
    }
    if (!state?.hasVoice && !context?.voicePreference) {
      missingInfo.push('Type de voix');
    }
    if (!state?.hasStyle && !context?.emotionStyle) {
      missingInfo.push('Style/ton');
    }
    if (!state?.hasContext && !context?.projectType) {
      missingInfo.push('Contexte d\'utilisation');
    }

    // Indicateurs que l'agent pose des questions
    const askingQuestions = [
      /quel.*\?/i,
      /quelle.*\?/i,
      /pouvez-vous/i,
      /pourriez-vous/i,
      /avez-vous/i,
      /me dire/i,
      /pr√©ciser/i,
      /plus.*informations/i,
      /\?.*$/m
    ].some(pattern => pattern.test(content));

    // Indicateurs que l'agent est pr√™t √† g√©n√©rer ou a g√©n√©r√©
    const readyToGenerate = [
      /g√©n√©rer/i,
      /cr√©er.*audio/i,
      /proc√©der/i,
      /lancer/i,
      /parfait/i,
      /excellent/i,
      /toutes.*informations/i,
      /pr√™t/i,
      /maintenant/i,
      /g√©n√©ration.*en.*cours/i
    ].some(pattern => pattern.test(content)) && state?.phase === 'generation';

    // Indicateurs qu'un audio a √©t√© g√©n√©r√©
    const audioGenerated = [
      /audio.*g√©n√©r√©/i,
      /fichier.*cr√©√©/i,
      /√©couter.*ci-dessous/i,
      /http.*\/audio\//i
    ].some(pattern => pattern.test(content));

    const needsMoreInfo = askingQuestions && !readyToGenerate && !audioGenerated;
    const canProceed = state?.phase === 'generation' || state?.phase === 'complete' || audioGenerated;

    // G√©n√©rer des suggestions bas√©es sur la phase et le contexte
    let suggestions: string[] = [];
    let nextSteps: string[] = [];

    switch (state?.phase) {
      case 'discovery':
        suggestions = [
          "D√©crivez votre projet audio en quelques mots",
          "Mentionnez le type de contenu (pub, formation, etc.)",
          "L'assistant va vous guider √©tape par √©tape"
        ];
        nextSteps = [
          "D√©crire le projet",
          "Fournir le contexte g√©n√©ral"
        ];
        break;

      case 'clarification':
        suggestions = [
          "R√©pondez √† la question pos√©e par l'assistant",
          "Soyez pr√©cis dans votre r√©ponse",
          "Une seule information √† la fois"
        ];
        nextSteps = [
          "R√©pondre √† la question",
          "Clarifier les d√©tails demand√©s"
        ];
        break;

      case 'generation':
        if (audioGenerated) {
          suggestions = [
            "L'audio a √©t√© g√©n√©r√© avec succ√®s",
            "Vous pouvez l'√©couter ci-dessus",
            "Demandez des ajustements si n√©cessaire"
          ];
          nextSteps = [
            "√âcouter l'audio",
            "T√©l√©charger le fichier",
            "Demander des modifications"
          ];
        } else {
          suggestions = [
            "L'assistant peut maintenant g√©n√©rer votre audio",
            "Confirmez pour proc√©der",
            "Vous pourrez √©couter et t√©l√©charger le r√©sultat"
          ];
          nextSteps = [
            "Confirmer la g√©n√©ration",
            "G√©n√©rer l'audio",
            "√âcouter le r√©sultat"
          ];
        }
        break;

      case 'complete':
        suggestions = [
          "Toutes les informations sont collect√©es",
          "L'audio est pr√™t ou g√©n√©r√©",
          "Nouvelles variations possibles"
        ];
        nextSteps = [
          "√âcouter l'audio final",
          "T√©l√©charger le fichier",
          "Cr√©er des variantes"
        ];
        break;

      default:
        suggestions = [
          "D√©crivez ce que vous souhaitez cr√©er",
          "L'assistant vous guidera pas √† pas"
        ];
        nextSteps = [
          "Commencer la conversation"
        ];
    }

    return {
      needsMoreInfo,
      missingInfo,
      suggestions,
      nextSteps,
      canProceed,
      readyToGenerate: readyToGenerate || audioGenerated
    };
  }

  static async generateProject(request: Request, response: Response): Promise<void> {
    console.log("üéØ generateProject appel√©");
    response.status(501).json({
      error: "Fonctionnalit√© en d√©veloppement",
      message: "La g√©n√©ration de projet compl√®te sera bient√¥t disponible"
    });
  }

  /**
   * Endpoint pour vider l'historique d'une session
   */
  static async clearHistory(request: Request, response: Response): Promise<void> {
    try {
      const { sessionId } = request.body;

      if (!sessionId) {
        response.status(400).json({
          success: false,
          error: "sessionId requis"
        });
        return;
      }

      audioAgent.clearHistory(sessionId);
      console.log("üóëÔ∏è Historique supprim√© pour session:", sessionId);

      response.json({
        success: true,
        message: "Historique supprim√© avec succ√®s",
        sessionId,
        timestamp: new Date().toISOString()
      });
    } catch (error) {
      console.error("‚ùå Erreur lors de la suppression:", error);
      response.status(500).json({
        success: false,
        error: "Erreur lors de la suppression de l'historique",
        details: error instanceof Error ? error.message : "Erreur inconnue"
      });
    }
  }

  /**
   * Endpoint pour obtenir le statut d'une session
   */
  static async getSessionStatus(request: Request, response: Response): Promise<void> {
    try {
      const { sessionId } = request.params;

      // Cette m√©thode pourrait √™tre ajout√©e √† l'agent pour obtenir le statut
      // Pour le moment, on retourne un statut basique
      response.json({
        success: true,
        sessionId,
        status: "active",
        timestamp: new Date().toISOString()
      });
    } catch (error) {
      response.status(500).json({
        success: false,
        error: "Erreur lors de la r√©cup√©ration du statut"
      });
    }
  }
}