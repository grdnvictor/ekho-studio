// backend/src/controllers/audio/AudioAgentController.ts
import { Request, Response } from "express";
import { audioAgent } from "@/agents/audio/audio-agent";
import { AudioAgentChatContractType } from "@/contracts/api/AudioAgentContracts";
import { ValidatedRequest } from "@/types";
import { AIMessage, HumanMessage } from "@langchain/core/messages";
import { ChatOpenAI } from "@langchain/openai";

interface AgentResult {
  messages: AIMessage[];
  conversationState: {
    phase: string;
    step: number;
  };
  historyLength: number;
  audioGenerated: boolean;
  audioUrl?: string;
  collectedInfo?: string[];
  sessionData?: any;
}

interface AnalysisResult {
  needsMoreInfo: boolean;
  missingInfo: string[];
  suggestions: string[];
  nextSteps: string[];
  canProceed: boolean;
  readyToGenerate: boolean;
  currentQuestion?: string;
  expectedResponseType?: string;
}

export class AudioAgentController {
  private static analysisLLM = new ChatOpenAI({
    temperature: 0.3,
    modelName: "local-model",
    openAIApiKey: "lm-studio",
    configuration: {
      baseURL: process.env.LM_STUDIO_URL || "http://localhost:1234/v1",
    },
  });

  static async chat(request: Request, response: Response): Promise<void> {
    console.log("üéØ === DEBUT AudioAgentController.chat ===");

    try {
      const validatedRequest = request as ValidatedRequest<AudioAgentChatContractType>;
      const { message, sessionId, context } = validatedRequest.validated.body;

      const finalSessionId = sessionId || `session_${Date.now()}`;

      console.log("üì¶ Donn√©es re√ßues:", {
        message: message?.slice(0, 100),
        sessionId: finalSessionId,
        context,
        hasContext: !!context
      });

      const config = {
        configurable: {
          thread_id: finalSessionId,
        },
      };

      // Cr√©er le message utilisateur
      const userMessage = new HumanMessage(message);

      console.log("üöÄ Envoi √† l'agent...");

      const result = await audioAgent.invoke(
        { messages: [userMessage] },
        config
      ) as AgentResult;

      const responseContent = result.messages[0].content;
      const conversationState = result.conversationState;

      console.log("üìù R√©ponse agent:", responseContent?.slice(0, 200));
      console.log("üìä √âtat conversation:", conversationState);
      console.log("üéµ Audio g√©n√©r√©:", result.audioGenerated);

      // Normaliser la phase pour le frontend
      const normalizedPhase = AudioAgentController.normalizePhase(conversationState?.phase);

      // Analyser la r√©ponse avec le LLM
      const analysis = await AudioAgentController.analyzeWithLLM(
        responseContent as string,
        conversationState,
        result.sessionData || {},
        message
      );

      // V√©rifier si un audio a √©t√© g√©n√©r√©
      let audioUrl = null;
      let audioData = null;

      if (result.audioGenerated && result.audioUrl) {
        audioUrl = result.audioUrl;
        audioData = {
          url: audioUrl,
          filename: audioUrl.split('/').pop() || 'audio.wav',
          mimeType: 'audio/wav',
          duration: 10
        };
        console.log("üéµ Audio g√©n√©r√© avec URL:", audioUrl);
      }

      // Construire la r√©ponse enrichie
      const responseData = {
        success: true,
        sessionId: finalSessionId,
        response: responseContent,
        needsMoreInfo: analysis.needsMoreInfo,
        missingInfo: analysis.missingInfo,
        suggestions: analysis.suggestions,
        nextSteps: analysis.nextSteps,
        canProceed: analysis.canProceed,
        readyToGenerate: analysis.readyToGenerate,
        conversationLength: result.historyLength,
        collectedInfo: result.collectedInfo || [],
        phase: normalizedPhase,

        // Informations audio
        audioGenerated: result.audioGenerated || false,
        audioUrl: audioUrl,
        audioData: audioData,

        context: result.sessionData || {},

        // M√©tadonn√©es de session
        metadata: {
          timestamp: new Date().toISOString(),
          processingTime: Date.now(),
          messageCount: result.historyLength,
          hasAudioContent: !!audioUrl
        }
      };

      // Log de la r√©ponse finale
      console.log("üéØ R√©ponse finale:", {
        success: responseData.success,
        phase: responseData.phase,
        audioGenerated: responseData.audioGenerated,
        collectedInfoCount: responseData.collectedInfo.length
      });

      response.status(200).json(responseData);

    } catch (error: unknown) {
      console.error("‚ùå Erreur dans AudioAgentController.chat:", error);

      // D√©terminer le type d'erreur et le code de statut appropri√©
      let statusCode = 500;
      let errorType = "INTERNAL_ERROR";
      let userMessage = "Erreur lors de la communication avec l'agent audio";

      if (error instanceof Error) {
        if (error.message.includes("Thread ID")) {
          statusCode = 400;
          errorType = "INVALID_SESSION";
          userMessage = "Identifiant de session invalide";
        } else if (error.message.includes("timeout") || error.message.includes("network")) {
          statusCode = 503;
          errorType = "SERVICE_UNAVAILABLE";
          userMessage = "Service temporairement indisponible";
        } else if (error.message.includes("rate limit")) {
          statusCode = 429;
          errorType = "RATE_LIMIT";
          userMessage = "Trop de requ√™tes, veuillez patienter";
        }
      }

      const errorResponse = {
        success: false,
        error: userMessage,
        errorType,
        details: error instanceof Error ? error.message : "Erreur inconnue",
        timestamp: new Date().toISOString(),
        suggestions: [
          "V√©rifiez votre connexion internet",
          "R√©essayez dans quelques instants",
          "Contactez le support si le probl√®me persiste"
        ]
      };

      console.log("üì§ R√©ponse d'erreur:", errorResponse);
      response.status(statusCode).json(errorResponse);
    }
  }

  /**
   * Normalise les phases pour le frontend
   */
  private static normalizePhase(phase: string | undefined): string {
    if (!phase) return 'discovery';

    const phaseMapping: Record<string, string> = {
      'error': 'clarification',
      'complete': 'complete',
      'discovery': 'discovery',
      'clarification': 'clarification',
      'generation': 'generation'
    };

    return phaseMapping[phase.toLowerCase()] || 'clarification';
  }

  /**
   * Analyse intelligente de la r√©ponse de l'agent avec LLM
   */
  private static async analyzeWithLLM(
    agentResponse: string,
    state: any,
    sessionData: any = {},
    userMessage: string
  ): Promise<AnalysisResult> {
    try {
      // Analyse directe sans LLM pour plus de rapidit√© et fiabilit√©
      const lowerResponse = agentResponse.toLowerCase();
      const analysis: AnalysisResult = {
        needsMoreInfo: false,
        missingInfo: [],
        suggestions: [],
        nextSteps: [],
        canProceed: false,
        readyToGenerate: false,
        currentQuestion: "",
        expectedResponseType: "text"
      };

      // D√©tection du type de question pos√©e par l'agent
      if (lowerResponse.includes('quel texte')) {
        analysis.needsMoreInfo = true;
        analysis.currentQuestion = "Quel texte veux-tu transformer ?";
        analysis.expectedResponseType = "text";
        analysis.suggestions = [
          "\"D√©couvrez nos offres exceptionnelles ce week-end !\"",
          "\"Bienvenue dans notre nouveau magasin\"",
          "\"Formation professionnelle en ligne disponible\""
        ];
      } else if (lowerResponse.includes('style') && lowerResponse.includes('üéØ')) {
        analysis.needsMoreInfo = true;
        analysis.currentQuestion = "Quel style pr√©f√®res-tu ?";
        analysis.expectedResponseType = "choice";
        analysis.suggestions = ["Dynamique üéØ", "Calme üòå", "Pro üíº"];
      } else if (lowerResponse.includes('pour qui') && lowerResponse.includes('üë¶')) {
        analysis.needsMoreInfo = true;
        analysis.currentQuestion = "Pour quel public ?";
        analysis.expectedResponseType = "choice";
        analysis.suggestions = ["Jeunes üë¶", "Familles üë®‚Äçüë©‚Äçüëß", "Pros üëî"];
      } else if (lowerResponse.includes('on g√©n√®re') || lowerResponse.includes('lance')) {
        analysis.needsMoreInfo = true;
        analysis.currentQuestion = "Pr√™t √† g√©n√©rer ?";
        analysis.expectedResponseType = "confirmation";
        analysis.suggestions = ["Oui, go ! üöÄ", "C'est parti ! ‚ú®", "Lance ! üéµ"];
        analysis.readyToGenerate = true;
      } else if (lowerResponse.includes('audio est pr√™t') || lowerResponse.includes('tadaaa')) {
        analysis.needsMoreInfo = false;
        analysis.canProceed = true;
        analysis.suggestions = ["Nouveau projet ! üÜï", "Super ! üôè", "J'adore ! ‚ù§Ô∏è"];
      }

      // D√©terminer les infos manquantes
      if (!sessionData.textContent) {
        analysis.missingInfo.push("Le texte √† vocaliser");
      }
      if (!sessionData.emotionStyle) {
        analysis.missingInfo.push("Le style");
      }
      if (!sessionData.targetAudience) {
        analysis.missingInfo.push("Le public cible");
      }

      // Prochaines √©tapes
      if (analysis.readyToGenerate) {
        analysis.nextSteps = ["Confirmer la g√©n√©ration", "L'audio sera cr√©√©"];
      } else if (analysis.missingInfo.length > 0) {
        analysis.nextSteps = ["R√©pondre √† la question", "Continuer la conversation"];
      } else {
        analysis.nextSteps = ["√âcouter l'audio", "Cr√©er un nouveau projet"];
      }

      analysis.canProceed = analysis.missingInfo.length === 0 || analysis.readyToGenerate;

      console.log("‚úÖ Analyse compl√©t√©e:", analysis);
      return analysis;
    } catch (error) {
      console.error("‚ùå Erreur analyse:", error);
      return this.fallbackAnalysis(agentResponse, state, sessionData);
    }
  }

  /**
   * G√©n√®re des suggestions contextuelles bas√©es sur la question
   */
  private static async generateContextualSuggestions(
    currentQuestion: string,
    agentResponse: string,
    sessionData: any
  ): Promise<string[]> {
    const lowerQuestion = currentQuestion.toLowerCase();
    const lowerResponse = agentResponse.toLowerCase();

    // D√©tection bas√©e sur les mots-cl√©s de l'agent
    if (lowerResponse.includes('quel texte') || lowerResponse.includes('texte')) {
      return [
        "Voici mon texte : \"Bienvenue chez nous\"",
        "\"D√©couvrez nos offres exceptionnelles\"",
        "Je veux cr√©er un texte avec vous"
      ];
    }

    if (lowerResponse.includes('style') && (lowerResponse.includes('dynamique') || lowerResponse.includes('calme') || lowerResponse.includes('pro'))) {
      return ["Dynamique üéØ", "Calme üòå", "Pro üíº"];
    }

    if (lowerResponse.includes('pour qui') || lowerResponse.includes('jeunes') || lowerResponse.includes('familles')) {
      return ["Jeunes üë¶", "Familles üë®‚Äçüë©‚Äçüëß", "Pros üëî"];
    }

    if (lowerResponse.includes('g√©n√®re') || lowerResponse.includes('lance') || lowerResponse.includes('on g√©n√®re')) {
      return ["Oui, go ! üöÄ", "Lance la g√©n√©ration !", "C'est parti !"];
    }

    // Suggestions par d√©faut bas√©es sur l'√©tat
    if (!sessionData.textContent) {
      return [
        "Publicit√© : \"D√©couvrez nos offres\"",
        "Narration : \"Il √©tait une fois\"",
        "Info : \"Bienvenue sur notre service\""
      ];
    }

    return ["Oui", "Continue", "C'est bon"];
  }

  /**
   * Analyse de fallback si le LLM √©choue
   */
  private static fallbackAnalysis(
    agentResponse: string,
    state: any,
    sessionData: any
  ): AnalysisResult {
    const lowerResponse = agentResponse.toLowerCase();
    const hasQuestion = agentResponse.includes('?');
    const isReadyToGenerate = lowerResponse.includes('on lance') || 
                             lowerResponse.includes('g√©n√©rer') ||
                             lowerResponse.includes('pr√™t');
    const audioGenerated = lowerResponse.includes('audio') && 
                          (lowerResponse.includes('g√©n√©r√©') || 
                           lowerResponse.includes('pr√™t'));

    return {
      needsMoreInfo: hasQuestion && !isReadyToGenerate && !audioGenerated,
      missingInfo: !sessionData?.textContent ? ['Texte √† vocaliser'] : [],
      suggestions: [
        "R√©pondez naturellement",
        "Donnez plus de d√©tails",
        "Passez √† l'√©tape suivante"
      ],
      nextSteps: audioGenerated 
        ? ["√âcouter l'audio", "T√©l√©charger", "Cr√©er un nouveau"]
        : ["Continuer la conversation", "Fournir les informations demand√©es"],
      canProceed: isReadyToGenerate || audioGenerated,
      readyToGenerate: isReadyToGenerate || audioGenerated
    };
  }

  static async generateProject(request: Request, response: Response): Promise<void> {
    console.log("üéØ generateProject appel√©");
    response.status(501).json({
      error: "Fonctionnalit√© en d√©veloppement",
      message: "La g√©n√©ration de projet compl√®te sera bient√¥t disponible"
    });
  }

  /**
   * Endpoint pour vider l'historique d'une session
   */
  static async clearHistory(request: Request, response: Response): Promise<void> {
    try {
      const { sessionId } = request.body;

      if (!sessionId) {
        response.status(400).json({
          success: false,
          error: "sessionId requis"
        });
        return;
      }

      audioAgent.clearHistory(sessionId);
      console.log("üóëÔ∏è Historique supprim√© pour session:", sessionId);

      response.json({
        success: true,
        message: "Historique supprim√© avec succ√®s",
        sessionId,
        timestamp: new Date().toISOString()
      });
    } catch (error) {
      console.error("‚ùå Erreur lors de la suppression:", error);
      response.status(500).json({
        success: false,
        error: "Erreur lors de la suppression de l'historique",
        details: error instanceof Error ? error.message : "Erreur inconnue"
      });
    }
  }

  /**
   * Endpoint pour obtenir le statut d'une session
   */
  static async getSessionStatus(request: Request, response: Response): Promise<void> {
    try {
      const { sessionId } = request.params;

      // Cette m√©thode pourrait √™tre ajout√©e √† l'agent pour obtenir le statut
      // Pour le moment, on retourne un statut basique
      response.json({
        success: true,
        sessionId,
        status: "active",
        timestamp: new Date().toISOString()
      });
    } catch (error) {
      response.status(500).json({
        success: false,
        error: "Erreur lors de la r√©cup√©ration du statut"
      });
    }
  }
}