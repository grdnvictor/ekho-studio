// backend/src/controllers/audio/AudioAgentController.ts
import { Request, Response } from "express";
import { audioAgent } from "@/agents/audio/audio-agent";
import { AudioAgentChatContractType } from "@/contracts/api/AudioAgentContracts";
import { ValidatedRequest } from "@/types";
import { SystemMessage, HumanMessage, AIMessage } from "@langchain/core/messages";

// Stockage en m√©moire des conversations (en production, utilisez Redis ou une DB)
const conversationMemory: Map<string, any[]> = new Map();

export class AudioAgentController {
  static async chat(request: Request, response: Response): Promise<void> {
    console.log("üéØ === DEBUT AudioAgentController.chat ===");

    try {
      const validatedRequest = request as ValidatedRequest<AudioAgentChatContractType>;
      const { message, sessionId, context } = validatedRequest.validated.body;

      const finalSessionId = sessionId || `session_${Date.now()}`;

      console.log("üì¶ Donn√©es re√ßues:", {
        message: message?.slice(0, 100),
        sessionId: finalSessionId,
        context
      });

      const config = {
        configurable: {
          thread_id: finalSessionId,
        },
      };

      // R√©cup√©rer l'historique de la conversation
      let conversationHistory = conversationMemory.get(finalSessionId) || [];
      console.log("üìö Historique r√©cup√©r√©:", conversationHistory.length, "messages");

      // Construire le message avec contexte si fourni
      let fullMessage = message;
      if (context) {
        const contextParts = [];
        if (context.targetAudience) contextParts.push(`Public cible: ${context.targetAudience}`);
        if (context.style) contextParts.push(`Style: ${context.style}`);
        if (context.duration) contextParts.push(`Dur√©e: ${context.duration}s`);
        if (context.emotion) contextParts.push(`√âmotion: ${context.emotion}`);

        if (contextParts.length > 0) {
          fullMessage = `${message}\n\nContexte d√©j√† fourni: ${contextParts.join(', ')}`;
        }
      }

      // Ajouter le nouveau message utilisateur √† l'historique
      const newUserMessage = new HumanMessage(fullMessage);
      conversationHistory.push(newUserMessage);

      // Pr√©parer les messages pour l'agent (syst√®me + historique)
      const systemPrompt = `Tu es l'Assistant Audio professionnel d'Ekho Studio. 

MISSION: Aider l'utilisateur √† cr√©er du contenu audio de qualit√© professionnelle.

CONTEXTE DE LA CONVERSATION:
- Tu as acc√®s √† tout l'historique de cette conversation
- Ne redemande PAS les informations d√©j√† fournies par l'utilisateur
- Fais r√©f√©rence aux √©l√©ments mentionn√©s pr√©c√©demment
- Progresse logiquement dans la collecte d'informations

√âTAPES OBLIGATOIRES:
1. Analyser TOUT l'historique de la conversation
2. Identifier les informations D√âJ√Ä collect√©es
3. Poser UNIQUEMENT les questions pour les informations manquantes
4. Recommander des solutions audio quand possible
5. Proposer la g√©n√©ration quand toutes les infos sont collect√©es

QUESTIONS ESSENTIELLES √Ä COLLECTER (si pas encore mentionn√©es):
- Quel est le contenu/texte √† vocaliser ?
- Quel est le public cible ? (√¢ge, contexte)
- Quelle est la dur√©e souhait√©e ?
- Quel style/ton ? (professionnel, chaleureux, dynamique, etc.)
- Quelle utilisation ? (pub radio, podcast, formation, etc.)

R√àGLES IMPORTANTES:
- EXAMINE d'abord l'historique complet avant de r√©pondre
- Ne pose UNE SEULE question √† la fois pour ne pas surcharger
- Si l'utilisateur a d√©j√† donn√© une info, n'en redemande JAMAIS
- Sois conversationnel et professionnel
- Propose des exemples concrets
- Utilise des √©mojis pour rendre √ßa plus engageant
- Fais des r√©sum√©s de ce qui a √©t√© collect√© quand appropri√©

R√©ponds toujours en fran√ßais avec un ton expert mais accessible.`;

      const allMessages = [
        new SystemMessage(systemPrompt),
        ...conversationHistory
      ];

      console.log("üöÄ Envoi √† l'agent avec", allMessages.length, "messages");

      const result = await audioAgent.invoke(
        { messages: allMessages },
        config
      );

      const responseContent = result.messages[0].content;
      console.log("üìù R√©ponse agent:", responseContent?.slice(0, 200));

      // Ajouter la r√©ponse de l'agent √† l'historique
      const agentMessage = new AIMessage({
        content: responseContent as string
      });
      conversationHistory.push(agentMessage);

      // Sauvegarder l'historique mis √† jour
      conversationMemory.set(finalSessionId, conversationHistory);
      console.log("üíæ Historique sauvegard√©:", conversationHistory.length, "messages");

      // Analyser la r√©ponse pour d√©terminer l'√©tat
      const analysis = AudioAgentController.analyzeResponse(
        responseContent ?
          (Array.isArray(responseContent)
            ? (typeof responseContent[0] === 'string'
              ? responseContent[0]
              : 'string' in responseContent[0]
                ? String(responseContent[0].string)
                : String(responseContent[0]))
            : String(responseContent))
          : '',
        conversationHistory
      );
      console.log("üìä Analyse:", analysis);

      response.status(200).json({
        success: true,
        sessionId: finalSessionId,
        response: responseContent,
        needsMoreInfo: analysis.needsMoreInfo,
        missingInfo: analysis.missingInfo,
        suggestions: analysis.suggestions,
        nextSteps: analysis.nextSteps,
        canProceed: analysis.canProceed,
        readyToGenerate: analysis.readyToGenerate,
        conversationLength: conversationHistory.length,
        collectedInfo: analysis.collectedInfo
      });

    } catch (error: unknown) {
      console.error("‚ùå Erreur:", error);

      response.status(500).json({
        success: false,
        error: "Erreur lors de la communication avec l'agent audio",
        details: error instanceof Error ? error.message : undefined,
      });
    }
  }

  /**
   * Analyse intelligente avec prise en compte de l'historique
   */
  private static analyzeResponse(content: string, history: any[]): {
    needsMoreInfo: boolean;
    missingInfo: string[];
    suggestions: string[];
    nextSteps: string[];
    canProceed: boolean;
    readyToGenerate: boolean;
    collectedInfo: string[];
  } {
    const lowerContent = content.toLowerCase();

    // Analyser l'historique pour voir ce qui a √©t√© collect√©
    const historyText = history
      .filter(msg => msg._getType() === 'human')
      .map(msg => msg.content.toLowerCase())
      .join(' ');

    console.log("üîç Analyse de l'historique:", historyText.slice(0, 200));

    const collectedInfo = [];
    const missingInfo = [];

    // V√©rifier les informations d√©j√† collect√©es dans l'historique
    if (historyText.includes('texte') || historyText.includes('contenu') || historyText.includes('script')) {
      collectedInfo.push('Contenu √† vocaliser');
    } else {
      missingInfo.push('Contenu √† vocaliser');
    }

    if (historyText.includes('public') || historyText.includes('audience') || historyText.includes('√¢ge')) {
      collectedInfo.push('Public cible');
    } else if (lowerContent.includes('public') || lowerContent.includes('audience')) {
      missingInfo.push('Public cible');
    }

    if (historyText.includes('dur√©e') || historyText.includes('seconde') || historyText.includes('minute')) {
      collectedInfo.push('Dur√©e');
    } else if (lowerContent.includes('dur√©e') || lowerContent.includes('long')) {
      missingInfo.push('Dur√©e souhait√©e');
    }

    if (historyText.includes('style') || historyText.includes('ton') || historyText.includes('professionnel') || historyText.includes('chaleureux')) {
      collectedInfo.push('Style/ton');
    } else if (lowerContent.includes('style') || lowerContent.includes('ton')) {
      missingInfo.push('Style/ton');
    }

    if (historyText.includes('radio') || historyText.includes('podcast') || historyText.includes('formation') || historyText.includes('publicit√©')) {
      collectedInfo.push('Utilisation');
    } else if (lowerContent.includes('utilisation') || lowerContent.includes('contexte')) {
      missingInfo.push('Contexte d\'utilisation');
    }

    // Indicateurs que l'agent pose des questions
    const askingQuestions = [
      /quel est/i,
      /quelle est/i,
      /pouvez-vous/i,
      /pourriez-vous/i,
      /avez-vous/i,
      /\?/,
      /pr√©ciser/i,
      /me dire/i,
      /plus d'informations/i
    ].some(pattern => pattern.test(content));

    // Indicateurs que l'agent est pr√™t √† g√©n√©rer
    const readyToGenerate = [
      /g√©n√©rer/i,
      /cr√©er l'audio/i,
      /proc√©der/i,
      /lancer/i,
      /parfait/i,
      /excellent/i,
      /toutes les informations/i,
      /maintenant/i
    ].some(pattern => pattern.test(content));

    const needsMoreInfo = askingQuestions && !readyToGenerate;

    console.log("üìä Infos collect√©es:", collectedInfo);
    console.log("üìä Infos manquantes:", missingInfo);

    return {
      needsMoreInfo,
      missingInfo,
      collectedInfo,
      suggestions: needsMoreInfo ? [
        "R√©pondez √† la question pos√©e par l'assistant",
        "L'assistant se souvient de ce que vous avez d√©j√† dit",
        "Soyez pr√©cis dans vos r√©ponses"
      ] : [
        "L'assistant va g√©n√©rer votre audio",
        "Toutes les informations semblent collect√©es",
        "Vous pourrez ensuite l'√©couter et le t√©l√©charger"
      ],
      nextSteps: needsMoreInfo ? [
        "R√©pondre √† la question",
        "Fournir les informations demand√©es"
      ] : [
        "Confirmer la g√©n√©ration",
        "G√©n√©rer l'audio",
        "√âcouter le r√©sultat"
      ],
      canProceed: !needsMoreInfo || readyToGenerate,
      readyToGenerate
    };
  }

  static async generateProject(request: Request, response: Response): Promise<void> {
    response.status(501).json({ error: "Not implemented yet" });
  }

  /**
   * Endpoint pour vider l'historique d'une session (optionnel)
   */
  static async clearHistory(request: Request, response: Response): Promise<void> {
    try {
      const { sessionId } = request.body;
      if (sessionId && conversationMemory.has(sessionId)) {
        conversationMemory.delete(sessionId);
        console.log("üóëÔ∏è Historique supprim√© pour session:", sessionId);
      }
      response.json({ success: true, message: "Historique supprim√©" });
    } catch (error) {
      response.status(500).json({ success: false, error: "Erreur lors de la suppression" });
    }
  }
}