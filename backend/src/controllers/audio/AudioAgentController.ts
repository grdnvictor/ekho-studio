// backend/src/controllers/audio/AudioAgentController.ts
import { Request, Response } from "express";
import { audioAgent } from "@/agents/audio/audio-agent";
import { AudioAgentChatContractType } from "@/contracts/api/AudioAgentContracts";
import { ValidatedRequest } from "@/types";
import { AIMessage, HumanMessage } from "@langchain/core/messages";

interface AgentResult {
  messages: AIMessage[];
  conversationState: {
    phase: string;
    step: number;
  };
  historyLength: number;
  audioGenerated: boolean;
  audioUrl?: string;
  collectedInfo?: string[];
  sessionData?: any;
}

export class AudioAgentController {
  static async chat(request: Request, response: Response): Promise<void> {
    console.log("üéØ === DEBUT AudioAgentController.chat ===");

    try {
      const validatedRequest = request as ValidatedRequest<AudioAgentChatContractType>;
      const { message, sessionId, context } = validatedRequest.validated.body;

      const finalSessionId = sessionId || `session_${Date.now()}`;

      console.log("üì¶ Donn√©es re√ßues:", {
        message: message?.slice(0, 100),
        sessionId: finalSessionId,
        context,
        hasContext: !!context
      });

      const config = {
        configurable: {
          thread_id: finalSessionId,
        },
      };

      // Cr√©er le message utilisateur
      const userMessage = new HumanMessage(message);

      console.log("üöÄ Envoi √† l'agent...");

      const result = await audioAgent.invoke(
        { messages: [userMessage] },
        config
      ) as AgentResult;

      const responseContent = result.messages[0].content;
      const conversationState = result.conversationState;

      console.log("üìù R√©ponse agent:", responseContent?.slice(0, 200));
      console.log("üìä √âtat conversation:", conversationState);
      console.log("üéµ Audio g√©n√©r√©:", result.audioGenerated);

      // Normaliser la phase pour le frontend
      const normalizedPhase = AudioAgentController.normalizePhase(conversationState?.phase);

      // Analyser la r√©ponse pour d√©terminer les actions possibles
      const analysis = AudioAgentController.analyzeAgentResponse(
        responseContent as string,
        conversationState,
        result.sessionData || {}
      );

      // Construire la r√©ponse enrichie
      const responseData = {
        success: true,
        sessionId: finalSessionId,
        response: responseContent,
        needsMoreInfo: analysis.needsMoreInfo,
        missingInfo: analysis.missingInfo,
        suggestions: analysis.suggestions,
        nextSteps: analysis.nextSteps,
        canProceed: analysis.canProceed,
        readyToGenerate: analysis.readyToGenerate,
        conversationLength: result.historyLength,
        collectedInfo: result.collectedInfo || [],
        phase: normalizedPhase,

        // Informations audio
        audioGenerated: result.audioGenerated || false,
        audioUrl: result.audioUrl || null,
        context: result.sessionData || {},

        // M√©tadonn√©es de session
        metadata: {
          timestamp: new Date().toISOString(),
          processingTime: Date.now(),
          messageCount: result.historyLength,
          hasAudioContent: !!result.audioUrl
        }
      };

      // Log de la r√©ponse finale
      console.log("üéØ R√©ponse finale:", {
        success: responseData.success,
        phase: responseData.phase,
        audioGenerated: responseData.audioGenerated,
        collectedInfoCount: responseData.collectedInfo.length
      });

      response.status(200).json(responseData);

    } catch (error: unknown) {
      console.error("‚ùå Erreur dans AudioAgentController.chat:", error);

      // D√©terminer le type d'erreur et le code de statut appropri√©
      let statusCode = 500;
      let errorType = "INTERNAL_ERROR";
      let userMessage = "Erreur lors de la communication avec l'agent audio";

      if (error instanceof Error) {
        if (error.message.includes("Thread ID")) {
          statusCode = 400;
          errorType = "INVALID_SESSION";
          userMessage = "Identifiant de session invalide";
        } else if (error.message.includes("timeout") || error.message.includes("network")) {
          statusCode = 503;
          errorType = "SERVICE_UNAVAILABLE";
          userMessage = "Service temporairement indisponible";
        } else if (error.message.includes("rate limit")) {
          statusCode = 429;
          errorType = "RATE_LIMIT";
          userMessage = "Trop de requ√™tes, veuillez patienter";
        }
      }

      const errorResponse = {
        success: false,
        error: userMessage,
        errorType,
        details: error instanceof Error ? error.message : "Erreur inconnue",
        timestamp: new Date().toISOString(),
        suggestions: [
          "V√©rifiez votre connexion internet",
          "R√©essayez dans quelques instants",
          "Contactez le support si le probl√®me persiste"
        ]
      };

      console.log("üì§ R√©ponse d'erreur:", errorResponse);
      response.status(statusCode).json(errorResponse);
    }
  }

  /**
   * Normalise les phases pour le frontend
   */
  private static normalizePhase(phase: string | undefined): string {
    if (!phase) return 'discovery';

    const phaseMapping: Record<string, string> = {
      'error': 'clarification',
      'complete': 'complete',
      'discovery': 'discovery',
      'clarification': 'clarification',
      'generation': 'generation'
    };

    return phaseMapping[phase.toLowerCase()] || 'clarification';
  }

  /**
   * Analyse intelligente de la r√©ponse de l'agent
   */
  private static analyzeAgentResponse(
    content: string,
    state: any,
    sessionData: any = {}
  ): {
    needsMoreInfo: boolean;
    missingInfo: string[];
    suggestions: string[];
    nextSteps: string[];
    canProceed: boolean;
    readyToGenerate: boolean;
  } {
    const lowerContent = content.toLowerCase();

    // D√©terminer les infos manquantes
    const missingInfo = [];
    if (!sessionData?.textContent) {
      missingInfo.push('Texte √† vocaliser');
    }

    // Indicateurs que l'agent pose des questions
    const askingQuestions = /\?/.test(content) && !lowerContent.includes('on lance');

    // Indicateurs que l'agent est pr√™t √† g√©n√©rer
    const readyToGenerate =
      (lowerContent.includes('on lance') ||
        lowerContent.includes('g√©n√©rer') ||
        lowerContent.includes('pr√™t') ||
        lowerContent.includes('go')) &&
      sessionData?.textContent;

    // Indicateurs qu'un audio a √©t√© g√©n√©r√©
    const audioGenerated =
      lowerContent.includes('audio') &&
      (lowerContent.includes('g√©n√©r√©') ||
        lowerContent.includes('pr√™t') ||
        lowerContent.includes('voil√†'));

    const needsMoreInfo = askingQuestions && !readyToGenerate && !audioGenerated;
    const canProceed = readyToGenerate || audioGenerated;

    // G√©n√©rer des suggestions contextuelles
    let suggestions: string[] = [];
    let nextSteps: string[] = [];

    if (audioGenerated) {
      suggestions = [
        "L'audio est pr√™t !",
        "Tu peux l'√©couter et le t√©l√©charger",
        "Dis 'nouveau' pour cr√©er un autre audio"
      ];
      nextSteps = [
        "√âcouter l'audio",
        "T√©l√©charger",
        "Cr√©er un nouveau"
      ];
    } else if (readyToGenerate) {
      suggestions = [
        "Tout est pr√™t pour g√©n√©rer",
        "R√©ponds 'oui' ou 'go' pour lancer",
        "Tu peux encore modifier si besoin"
      ];
      nextSteps = [
        "Confirmer la g√©n√©ration",
        "Modifier les param√®tres"
      ];
    } else {
      suggestions = [
        "Continue la conversation naturellement",
        "L'assistant te guide √©tape par √©tape",
        "Pas besoin de tout dire d'un coup"
      ];
      nextSteps = [
        "R√©pondre √† la question",
        "Fournir plus de d√©tails"
      ];
    }

    return {
      needsMoreInfo,
      missingInfo,
      suggestions,
      nextSteps,
      canProceed,
      readyToGenerate: readyToGenerate || audioGenerated
    };
  }

  static async generateProject(request: Request, response: Response): Promise<void> {
    console.log("üéØ generateProject appel√©");
    response.status(501).json({
      error: "Fonctionnalit√© en d√©veloppement",
      message: "La g√©n√©ration de projet compl√®te sera bient√¥t disponible"
    });
  }

  /**
   * Endpoint pour vider l'historique d'une session
   */
  static async clearHistory(request: Request, response: Response): Promise<void> {
    try {
      const { sessionId } = request.body;

      if (!sessionId) {
        response.status(400).json({
          success: false,
          error: "sessionId requis"
        });
        return;
      }

      audioAgent.clearHistory(sessionId);
      console.log("üóëÔ∏è Historique supprim√© pour session:", sessionId);

      response.json({
        success: true,
        message: "Historique supprim√© avec succ√®s",
        sessionId,
        timestamp: new Date().toISOString()
      });
    } catch (error) {
      console.error("‚ùå Erreur lors de la suppression:", error);
      response.status(500).json({
        success: false,
        error: "Erreur lors de la suppression de l'historique",
        details: error instanceof Error ? error.message : "Erreur inconnue"
      });
    }
  }

  /**
   * Endpoint pour obtenir le statut d'une session
   */
  static async getSessionStatus(request: Request, response: Response): Promise<void> {
    try {
      const { sessionId } = request.params;

      // Cette m√©thode pourrait √™tre ajout√©e √† l'agent pour obtenir le statut
      // Pour le moment, on retourne un statut basique
      response.json({
        success: true,
        sessionId,
        status: "active",
        timestamp: new Date().toISOString()
      });
    } catch (error) {
      response.status(500).json({
        success: false,
        error: "Erreur lors de la r√©cup√©ration du statut"
      });
    }
  }
}